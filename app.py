import face_recognition
import picamera
import numpy as np
from flask import Flask, jsonify, request, render_template

app = Flask(__name__, static_url_path='/static')

@app.route('/on_load')
def on_load():

    # Get a reference to the Raspberry Pi camera.
    # If this fails, make sure you have a camera connected to the RPi and that you
    # enabled your camera in raspi-config and rebooted first.
    camera = picamera.PiCamera()
    camera.resolution = (320, 240)
    output = np.empty((240, 320, 3), dtype=np.uint8)

    # Get and encode known images
    #me = face_recognition.load_image_file("../test-images/matt-1.jpg")
    #me_encoding = face_recognition.face_encodings(me)[0]

    matt1_encoding = np.array([-7.62386397e-02, 3.01904138e-03, -2.38237213e-02, -5.60772009e-02,
     -8.77503380e-02,  3.29113789e-02, -5.91115952e-02, -1.35576516e-01,
      1.77747339e-01, -4.71483767e-02, 1.53783932e-01, -4.02787291e-02,
     -2.59692281e-01, -1.16651133e-01, 4.36959602e-02, 5.17890081e-02,
     -1.11357808e-01, -9.79429781e-02, -6.68500215e-02, -6.63109869e-02,
      2.59716548e-02,  5.23214266e-02, 5.82300313e-02, 4.12139855e-02,
     -1.22904457e-01, -3.29092592e-01, -1.35069624e-01, -2.05371961e-01,
      6.08246922e-02, -5.57530746e-02, 2.32655518e-02, 5.90997934e-02,
     -1.47523180e-01, -5.32861054e-02, 6.31168112e-02, 3.03123780e-02,
     -7.61529654e-02, -7.93362185e-02, 1.77059799e-01, -4.45145331e-02,
     -1.70076221e-01, -1.13955051e-01, 5.38403988e-02, 1.50000006e-01,
      1.59394413e-01,  5.75799383e-02, -1.53327361e-02, -7.95690119e-02,
      1.89084098e-01, -2.06442505e-01, 1.01871505e-01, 1.27010211e-01,
      2.82372087e-01, 5.64930514e-02, 1.50766015e-01, -1.28655583e-01,
      1.20605774e-01, 1.35679498e-01, -3.39231938e-01, 8.73107761e-02,
     -2.52260081e-03, -8.67664516e-02, -4.01429366e-03, 8.34699254e-03,
      2.03773916e-01, 1.30174741e-01, -6.89220056e-02, -1.67036444e-01,
      2.12155238e-01, -1.87735051e-01, -3.92972007e-02, 1.87190309e-01,
     -9.88179967e-02, -2.33143762e-01, -2.66150951e-01, -5.97811416e-02,
      3.69145930e-01, 1.51237547e-01, -1.75035641e-01, -1.48803517e-02,
     -7.94725865e-02, -1.01132117e-01, 4.81006131e-03, 4.05841023e-02,
     -1.03973173e-01, -1.11971922e-01, -6.84380755e-02, -5.84585369e-02,
      2.19163150e-01, -6.73950315e-02, -2.84745470e-02, 2.53344089e-01,
      1.00616096e-02, 3.80974412e-02, -4.52668406e-03, -6.36894489e-03,
     -7.18271434e-02, 7.44583085e-05, -1.03249531e-02, -2.80063786e-02,
      7.96435773e-03, -7.81379864e-02, 2.19520405e-02, 7.27147982e-02,
     -2.23828897e-01, 1.73344612e-01, 8.77884449e-04, -4.52344492e-02,
     -4.88692382e-03, -1.00253820e-01, -8.83731544e-02, -9.03083943e-03,
      1.98479578e-01, -3.58494580e-01, 1.87033236e-01, 1.05240174e-01,
      6.79169968e-02, 1.56795323e-01, -6.83606043e-02, 3.62067968e-02,
      7.23584695e-03, -1.32431507e-01, -2.11615205e-01, -8.07123259e-02,
      9.09725055e-02, -1.04741022e-01, -4.44041304e-02, 3.49725410e-02])

    will_encoding = np.array([-1.46550432e-01, 6.19738735e-02, 1.17102906e-01, 6.24578074e-02,
     -1.02993339e-01, 8.16372707e-02, -2.51564793e-02, 3.08810938e-02,
      1.60502896e-01, -7.63921738e-02, 1.97130352e-01, -3.77940014e-04,
     -1.52249813e-01, 1.07838713e-01, -5.51417880e-02, 1.53314650e-01,
     -1.05878182e-01, -6.75635561e-02, -1.15034975e-01, -6.04450889e-02,
     -1.23572927e-02, 8.10826346e-02, -6.83894232e-02, 5.57739474e-03,
     -1.50017396e-01, -3.42345238e-01, -9.73597914e-02, -6.94121569e-02,
      2.47160904e-02, -1.46301836e-01, -2.02490184e-02, -6.17793165e-02,
     -1.38713032e-01, -3.82386521e-02, 2.68683843e-02, 5.34176528e-02,
     -4.95258421e-02, -3.06281708e-02, 1.81930751e-01, 2.73273718e-02,
     -1.46340474e-01, 4.42918912e-02, 5.49996495e-02, 2.98895806e-01,
      8.55882168e-02, 1.01737991e-01, -7.49959797e-03, -9.09191929e-03,
      9.92664844e-02, -2.96188325e-01, 1.22161768e-01, 2.85904594e-02,
      1.77596569e-01, 9.82161388e-02, 9.74712148e-02, -1.56645417e-01,
     -3.53183374e-02, 1.84957504e-01, -1.77275062e-01, 1.79927334e-01,
      2.62351558e-02, -7.79332146e-02, 3.21322493e-03, -5.12982383e-02,
      2.36876667e-01, 1.45619199e-01, -1.22591376e-01, -1.41313300e-01,
      1.06840141e-01, -1.26748681e-01, 3.58940940e-03, 3.61814797e-02,
     -8.15792475e-03, -2.27375150e-01, -2.81392872e-01, 1.46685883e-01,
      4.27225798e-01, 1.61259860e-01, -2.31827989e-01, -3.35271023e-02,
      2.35664919e-02, -2.89039239e-02, 6.23971634e-02, 1.10025547e-01,
     -6.80943280e-02, -3.23436521e-02, -4.99577373e-02, 6.75653759e-03,
      1.90081865e-01, 3.10827419e-02, -3.69435139e-02, 1.75209075e-01,
     -3.30384299e-02, 2.11250000e-02, -1.26598980e-02, 4.62603308e-02,
     -1.43027231e-01, -8.77583493e-03, -3.92683931e-02, 2.50279047e-02,
      2.09428929e-02, -9.78486799e-03, 1.42103657e-02, 8.52269530e-02,
     -1.36844605e-01, 2.14866430e-01, -8.25658366e-02, -4.14033644e-02,
      1.17376447e-04, 8.22296962e-02, -1.26826614e-01, -6.73010596e-04,
      1.93403214e-01, -3.06911528e-01, 1.76659703e-01, 1.45902589e-01,
     -6.51041865e-02, 1.85507417e-01, 5.35532422e-02, 8.03702921e-02,
      4.81764600e-02, 9.73244607e-02, -2.00636879e-01, -7.34169409e-02,
      5.61925545e-02, -1.34473324e-01, 5.24781868e-02, 5.43045886e-02])

    known_face_encodings = [will_encoding, matt1_encoding]


    # Initialize some variables
    face_locations = []
    face_encodings = []

    names = []

    # Grab a single frame of video from the RPi camera as a numpy array
    camera.capture(output, format="rgb")

    # Find all the faces and face encodings in the current frame of video
    face_locations = face_recognition.face_locations(output)
    print("Found {} faces in image.".format(len(face_locations)))
    if(len(face_locations) == 0):
        names.append("Nobody")
        camera.close()
        return jsonify(faces=names)
        
    face_encodings = face_recognition.face_encodings(output, face_locations)

    # Loop over each face found in the frame to see if it's someone we know.
    for ind, face_encoding in enumerate(face_encodings):

        for index, known_face_encoding in enumerate(known_face_encodings):
            
            # See if the face is a match for the known face(s)
            match = face_recognition.compare_faces([known_face_encoding], face_encoding)

            if match[0]:
                if index == 0:
                    names.append("Will")
                if index == 1:
                    names.append("Matt")

    print(names)
    camera.close()
    return jsonify(faces=names)

@app.route('/', methods=['GET', 'POST'])
def index():
    print("landed on hompage")
    return render_template('index.html')


if __name__ == "__main__":
    # host='0.0.0.0' means the web app is available to any device on the network
    app.run(host='0.0.0.0', port=5001, debug=True)
